{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reading text from files\n",
    "\n",
    "We use python 3.4 to read text from two files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = open('../data/abipon-latin1.txt', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Abip\\xf3n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = open('../data/abipon-utf8.txt', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Abipo\\xcc\\x81n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary content of the two files is obviously different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1) == len(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to decode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 4: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0a4621444d34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 4: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "s1.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abipón'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.decode('latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. That looks about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AbipoÌ\\x81n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.decode('latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abipón'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! So the content of the two files may be the same after all!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Textual data may be represented in files in different [character encodings](https://en.wikipedia.org/wiki/Character_encoding).\n",
    "- Common encodings are \n",
    "  - [ASCII](https://en.wikipedia.org/wiki/ASCII)\n",
    "  - Latin 1, aka [ISO 8859-1](https://en.wikipedia.org/wiki/ISO/IEC_8859-1) Western Europe\n",
    "  - CP-1252, aka [Windows-1252](https://en.wikipedia.org/wiki/Windows-1252)\n",
    "  - macroman, aka [Mac OS Roman](https://en.wikipedia.org/wiki/Mac_OS_Roman)\n",
    "  - [UTF-8](https://en.wikipedia.org/wiki/UTF-8)\n",
    "- All the above encodings are compatible with ASCII, i.e. ASCII-only text will be encoded\n",
    "  identically in all these encodings.\n",
    "- But generally comparing text in different encodings does not make sense.\n",
    "- UTF-8 is the only Unicode encoding of the ones listed above, i.e. it can encode all characters\n",
    "  defined in the [Unicode standard](https://en.wikipedia.org/wiki/Unicode).\n",
    "- It is impossible in general to automatically detect the encoding used in a file, since\n",
    "  for example everything can be \"decoded\" as Latin 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of text in software: Unicode\n",
    "\n",
    "Software systems need a unified internal representation of textual data. This is typically\n",
    "either a unicode encoding like UTF-8 (R) or UTF-16 (Windows) or an implementation of\n",
    "Unicode (Python).\n",
    "\n",
    "The advantages of implementing the Unicode standard are:\n",
    "- character properties:\n",
    "  - category (letter [uppercase|lowercase|...], punctuation, symbol, ...)\n",
    "  - script (Coptic, Cyrillic, ...)\n",
    "- rules for normalization, decomposition, collation, bidirectional display\n",
    "\n",
    "So let's see how our data looks internally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = s1.decode('latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = s2.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm. So this is not WYSIWYG. Looking the same is not enough to pass as identity in Unicode. There are many instances where the fonts rendering the glyphs for different sequences of unicode code points will look the same, because\n",
    "- different scripts may have characters looking alike, e.g. the cyrillic letter а and the latin letter a\n",
    "- there are different unicode sequences representing the same glyphs, e.g. through the use of combining accents or diacritics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find out what's going on here with the help of the [unicodedata](https://docs.python.org/3/library/unicodedata.html) library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATIN CAPITAL LETTER A\n",
      "LATIN SMALL LETTER B\n",
      "LATIN SMALL LETTER I\n",
      "LATIN SMALL LETTER P\n",
      "LATIN SMALL LETTER O WITH ACUTE\n",
      "LATIN SMALL LETTER N\n"
     ]
    }
   ],
   "source": [
    "for c in s1:\n",
    "    print(unicodedata.name(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATIN CAPITAL LETTER A\n",
      "LATIN SMALL LETTER B\n",
      "LATIN SMALL LETTER I\n",
      "LATIN SMALL LETTER P\n",
      "LATIN SMALL LETTER O\n",
      "COMBINING ACUTE ACCENT\n",
      "LATIN SMALL LETTER N\n"
     ]
    }
   ],
   "source": [
    "for c in s2:\n",
    "    print(unicodedata.name(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the difference comes from the fact that in `s2`, the ó has been composed from two unicode code points. Fortunately unicode has a concept of [equivalence](https://en.wikipedia.org/wiki/Unicode_equivalence) which solves this problem, and [normalization](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization) it the way to assess equivalence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either force the canonical composition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == unicodedata.normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or canonical decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.normalize('NFD', s1) == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "- Naive string comparisons do not work when text is encoded differently.\n",
    "- It is also not that easy when text is encoded with the same encoding ...\n",
    "- ... and it is not easy with unicode either.\n",
    "- But unicode provides the tools (normalization!) to make it work.\n",
    "- The unicode support in python does not mean normalization is applied implicitely before comparing strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
